{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import r2_score"
      ],
      "metadata": {
        "id": "Y7iEaRxrwSOy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('statistics_output.csv', index_col=0)\n",
        "y = df['Yes Vote 2014']\n",
        "x = df.filter(['SNP Vote 2014', 'Claimant Count 2014', 'Low-Skilled Employment 2014', 'Population 2014'])"
      ],
      "metadata": {
        "id": "61UPxH9BwVM3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reg(x, y):\n",
        "    # fit linear regression model and return adjusted R2, p-value, aic and bic values\n",
        "    model = sm.OLS(y, sm.add_constant(x)).fit()\n",
        "    rsquared_adj = model.rsquared_adj\n",
        "    f_pvalue = model.f_pvalue\n",
        "    aic = model.aic\n",
        "    bic = model.bic\n",
        "\n",
        "    return rsquared_adj, f_pvalue, aic, bic"
      ],
      "metadata": {
        "id": "YKu2d5cmSXzT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define variables\n",
        "rsquared_adj_list, f_pvalue_list, aic_list, bic_list, feature_list = [], [], [], [], []\n",
        "numb_features = []\n",
        "\n",
        "# loop over k features in the dataframe\n",
        "for k in range(1, len(x.columns) + 1):\n",
        "  # loop over all possible model combinations and append the results to the evaltions metric lists\n",
        "  for combo in itertools.combinations(x.columns, k):\n",
        "    temp_result = reg(x[list(combo)], y)\n",
        "    rsquared_adj_list.append(temp_result[0])\n",
        "    f_pvalue_list.append(temp_result[1])\n",
        "    aic_list.append(temp_result[2])\n",
        "    bic_list.append(temp_result[3])\n",
        "    feature_list.append(combo)\n",
        "    numb_features.append(len(combo))   \n",
        "\n",
        "# store results in a dataframe and export to CSV\n",
        "df_res = pd.DataFrame({'numb_features': numb_features, 'features': feature_list, 'adj_R2': rsquared_adj_list, 'p-val': f_pvalue_list, 'aic': aic_list,'bic': bic_list})\n",
        "df_res_max = df_res[df_res.groupby('numb_features')['adj_R2'].transform(max) == df_res['adj_R2']]\n",
        "df_res_max.to_csv('best_subset.csv')"
      ],
      "metadata": {
        "id": "Z_IGn8khQ3BG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['Yes Vote 2014']\n",
        "x = df.filter(['SNP Vote 2014', 'Claimant Count 2014', 'Population 2014'])\n",
        "\n",
        "# set the number of folds for the cross validation\n",
        "n_folds = 10\n",
        "\n",
        "# create a scores list\n",
        "scores = []\n",
        "\n",
        "# create a KFold object with the desired number of folds\n",
        "kf = KFold(n_splits=n_folds)\n",
        "\n",
        "# split the data into folds\n",
        "for train_index, test_index in kf.split(x):\n",
        "  # split the data into training and testing sets\n",
        "  x_train, x_test = x.iloc[train_index], x.iloc[test_index]\n",
        "  y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "  # fit a model on the training data and evaluate it on the test data\n",
        "  model = sm.OLS(y_train, sm.add_constant(x_train))\n",
        "  results = model.fit()\n",
        "  x_test_with_const = sm.add_constant(x_test)\n",
        "  y_pred = results.predict(x_test_with_const)\n",
        "  score = r2_score(y_test, y_pred)\n",
        "  \n",
        "  # record the score for this fold\n",
        "  scores.append(score)\n",
        "\n",
        "# calculate the mean and standard deviation of the scores\n",
        "mean_score = np.mean(scores)\n",
        "std_dev = np.std(scores)"
      ],
      "metadata": {
        "id": "ciiluqDPyg8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following functions are just copied from the cleaning.py file"
      ],
      "metadata": {
        "id": "ce-HX4I3U-HI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_string_to_float(df, columns: list):\n",
        "    \"\"\"\n",
        "    Convert a string to a floating point number (using float to allow conversion of NaN values)\n",
        "     - Remove commas\n",
        "     - Remove spaces\n",
        "     - Convert null value indicators used by data providers (NOMIS, UK Parliament etc.) to NaN: ('-', '*')\n",
        "     - Convert to float type\n",
        "    \"\"\"\n",
        "    df[columns] = df[columns].astype(str)\n",
        "    # remove commas and spaces\n",
        "    df.replace(',', '', regex=True, inplace=True)\n",
        "    df.replace(' ', '', regex=True, inplace=True)\n",
        "    # replace values that contain null value indicator characters with NaN (if a value contains a null value indicator character and additional characters it will still be replaced with NaN as some data providers add additional spaces after thier null value indicator character and therefore just replacing the null value indicator character would result in the dataframe holding values of NaN with additonal spaces, which would raise an exception when converting to float)\n",
        "    for column in columns:\n",
        "        for value in list(df[column].values):\n",
        "            for char in ['-', '*']:\n",
        "                if char in value:\n",
        "                    df[column].replace(value, 'NaN', inplace=True)\n",
        "    # convert values to float\n",
        "    df[columns] = df[columns].astype(float)\n",
        "    return df"
      ],
      "metadata": {
        "id": "nHyJXmdWUwyA"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_percentage_to_float(df, columns: list):\n",
        "    \"\"\"\n",
        "    Convert a percentage (string) to a floating point number (using float to allow conversion of NaN values)\n",
        "     - Remove percentage sign\n",
        "     - Remove spaces\n",
        "     - Convert null value indicators used by data providers (NOMIS, UK Parliament etc.) to NaN: ('-', '*', '!')\n",
        "     - Convert to float type\n",
        "     - Divide by 100 (rounded to 3 decimal places)\n",
        "    \"\"\"\n",
        "    df[columns] = df[columns].astype(str)\n",
        "    # remove percentage and spaces\n",
        "    df.replace('%', '', regex=True, inplace=True)\n",
        "    df.replace(' ', '', regex=True, inplace=True)\n",
        "    # replace values that contain null value indicator characters with NaN (if a value contains a null value indicator character and additional characters it will still be replaced with NaN as some data providers add additional spaces after thier null value indicator character and therefore just replacing the null value indicator character would result in the dataframe holding values of NaN with additonal spaces, which would raise an exception when converting to float)\n",
        "    for column in columns:\n",
        "        for value in list(df[column].values):\n",
        "            for char in ['-', '*', '!']:\n",
        "                if char in value:\n",
        "                    df[column].replace(value, 'NaN', inplace=True)\n",
        "    # convert values to float\n",
        "    df[columns] = df[columns].astype(float)\n",
        "    # divide each value by 100 and round to 3 decimal places\n",
        "    for column in columns:\n",
        "        for value in list(df[column].values):\n",
        "            df[column].replace(value, round(value/100, 3), inplace=True)\n",
        "    return df"
      ],
      "metadata": {
        "id": "p_dIl8q3U0tC"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_la_to_common_name(df):\n",
        "    \"\"\"\n",
        "    Convert dataframe index names (local authorities) to common names\n",
        "    \"\"\"\n",
        "    # define the common list of local authorities to use when checking converted index names list\n",
        "    la_list = ['Aberdeen City', 'Aberdeenshire', 'Angus', 'Argyll And Bute', 'City Of Edinburgh', 'City Of Glasgow', 'Clackmannanshire', 'Dumfries And Galloway', 'Dundee City', 'East Ayrshire', 'East Dunbartonshire', 'East Lothian', 'East Renfrewshire', 'Falkirk', 'Fife', 'Highland', 'Inverclyde', 'Midlothian', 'Moray', 'Na H-Eileanan Siar', 'North Ayrshire', 'North Lanarkshire', 'Orkney Islands', 'Perth And Kinross', 'Renfrewshire', 'Scottish Borders', 'Shetland Islands', 'South Ayrshire', 'South Lanarkshire', 'Stirling', 'West Dunbartonshire', 'West Lothian']\n",
        "    # convert index header to 'Local Authority'\n",
        "    df.index.names = ['Local Authority']\n",
        "    for local_authority in df.index:\n",
        "        # define variable to hold the correctly formatted local_authority variable\n",
        "        new_local_authority = local_authority\n",
        "        # replace '&' with 'and'\n",
        "        if '&' in local_authority:\n",
        "            new_local_authority = local_authority.replace('&', 'and')\n",
        "        # replace variations of 'Na H-Eileanan Siar' with common name\n",
        "        if local_authority.lower() == 'western isles - comhairle nan eilean siar' or local_authority.lower() == 'comhairle nan eilean siar' or local_authority.lower() == 'eilean siar' or local_authority.lower() == 'na h-eileanan an iar':\n",
        "            new_local_authority = 'Na H-Eileanan Siar'\n",
        "        # replace variations of 'Glasgow City' with common name\n",
        "        if local_authority.lower() == 'glasgow city' or local_authority.lower() == 'glasgow':\n",
        "            new_local_authority = 'City Of Glasgow'\n",
        "        if local_authority.lower() == 'edinburgh, city of':\n",
        "            new_local_authority = 'City Of Edinburgh'\n",
        "        if local_authority.lower() == 'dundee':\n",
        "            new_local_authority = 'Dundee City'\n",
        "        if local_authority.lower() == 'ork':\n",
        "            new_local_authority = 'Orkney Islands'\n",
        "        if local_authority.lower() == 'shetland':\n",
        "            new_local_authority = 'Shetland Islands'\n",
        "        # convert each LA to title case\n",
        "        df.rename(index={local_authority: new_local_authority.title()}, inplace=True)\n",
        "    # sort dataframe to allow comparison with common list\n",
        "    df = df.sort_index()\n",
        "    # raise ValueError excpetion if the converted index names list is not equal to the common list of local authorities\n",
        "    for la in df.index.tolist():\n",
        "        if la not in la_list:\n",
        "            raise ValueError(f'Converted index names list is not equal to the common list of local authorities. Compare lists and edit convert_la_to_common_name() to enable the function to correct the difference in values {la}')\n",
        "    return df"
      ],
      "metadata": {
        "id": "0X-84jcLU3Zb"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "it4umS4yMG7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "electorate_df = pd.read_csv('electoral_data.csv', index_col=0)\n",
        "electorate_df = electorate_df.filter(['2021 Dec Total electorate [note 10]'])\n",
        "electorate_df.rename(columns={'2021 Dec Total electorate [note 10]': 'Electorate 2021'}, inplace=True)\n",
        "convert_string_to_float(electorate_df, ['Electorate 2021'])\n",
        "electorate_df = convert_la_to_common_name(electorate_df)\n",
        "\n",
        "turnout_df = pd.read_csv('referendum_stats.csv', index_col=0)\n",
        "turnout_df = turnout_df.filter(['Adjusted turnout (\\'Valid vote turnout\\', excl. invalid votes)'])\n",
        "turnout_df.rename(columns={'Adjusted turnout (\\'Valid vote turnout\\', excl. invalid votes)': 'Turnout'}, inplace=True)\n",
        "turnout_df = convert_la_to_common_name(turnout_df)\n",
        "convert_percentage_to_float(turnout_df, ['Turnout'])\n",
        "\n",
        "model = sm.OLS(df['Yes Vote 2014'], sm.add_constant(df.filter(['SNP Vote 2014', 'Claimant Count 2014', 'Low-Skilled Employment 2014', 'Population 2014']))).fit()\n",
        "yes_pred = model.predict(sm.add_constant(df.filter(['SNP Vote 2019', 'Claimant Count 2022', 'Low-Skilled Employment 2021', 'Population 2020'])))\n",
        "# due to no available data for low-skilled employmnet for orkney islands and shetland islands, 2 feature model used for predicting yes vote in these 2 LAs\n",
        "model_for_nan_vals = sm.OLS(df['Yes Vote 2014'], sm.add_constant(df.filter(['SNP Vote 2014', 'Claimant Count 2014', 'Population 2014']))).fit()\n",
        "yes_pred_for_nan_vals = model_for_nan_vals.predict(sm.add_constant(df.filter(['SNP Vote 2019', 'Claimant Count 2022', 'Population 2020'])))\n",
        "\n",
        "result_df = pd.concat([df['Yes Vote 2014'], yes_pred], axis=1, ignore_index=False)\n",
        "result_df.columns.values[1] = 'Predicted Yes Vote (Percentage)'\n",
        "result_df.loc['Orkney Islands', 'Predicted Yes Vote (Percentage)'] = yes_pred_for_nan_vals.loc['Orkney Islands']\n",
        "result_df.loc['Shetland Islands', 'Predicted Yes Vote (Percentage)'] = yes_pred_for_nan_vals.loc['Shetland Islands']\n",
        "result_df['Predicted Yes Vote (Percentage)'] = round(result_df['Predicted Yes Vote (Percentage)'], 3)\n",
        "\n",
        "result_df = pd.concat([result_df, electorate_df, turnout_df], axis=1, ignore_index=False)\n",
        "result_df['Predicted Yes Vote (Absolute)'] = round(result_df['Electorate 2021'] * result_df['Turnout'] * result_df['Predicted Yes Vote (Percentage)'], 0)\n",
        "result_df['Predicted No Vote (Absolute)'] = round(result_df['Electorate 2021'] * result_df['Turnout'] * (1-result_df['Predicted Yes Vote (Percentage)']), 0)\n",
        "\n",
        "result_df.to_csv('predicted_votes.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93xcPo6cU8Mr",
        "outputId": "15c2534f-3427-4413-9629-77aa0f4a2724"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/statsmodels/tsa/tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
            "  x = pd.concat(x[::order], 1)\n"
          ]
        }
      ]
    }
  ]
}